{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeong777/Python-Quest/blob/main/hair_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xubTPnHy2Dl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 로드\n",
        "!pip install efficientnet_pytorch\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import copy\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from tqdm import tqdm\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "random_seed = 100\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "id": "jhOVozIvy9_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 컨트롤 부분\n",
        "# 모델1~6 학습 시 바꿔야 하는 것 (이거 하나만 바꾸면 됨)\n",
        "train_name = 'model1' # check point //  model 1, 2, 3, 4, 5, 6\n",
        "# 사용할 모델\n",
        "model_name = 'efficientnet-b0'  # check point // EfficientNet B0 to B7\n",
        "# 파라미터\n",
        "hyper_param_batch = 4  # check point // 배치 사이즈 # 기본 4 이상( > 아웃풋4)\n",
        "num_epochs = 1 # check point // 에폭 설정"
      ],
      "metadata": {
        "id": "z2pavbrkKSzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터경로\n",
        "data_train_path ='/content/drive/MyDrive/sdproject/train_data/'+train_name+'/train'\n",
        "data_validation_path = '/content/drive/MyDrive/sdproject/train_data/'+train_name+'/validation'\n",
        "# 여기에 모델.pt가 save\n",
        "PATH = '/content/drive/MyDrive/sdproject/scalp_weights/'"
      ],
      "metadata": {
        "id": "NARYAKDry-Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델\n",
        "num_classes = 4  # 고정값 아웃풋 0 1 2 3 // 4가지\n",
        "model = EfficientNet.from_pretrained(model_name, num_classes=num_classes) /\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "B3MsVLtM0sQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 전처리\n",
        "# 전처리규칙선언\n",
        "def func(x):\n",
        "    return x.rotate(90)\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BOX),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.Lambda(func),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "transforms_val = transforms.Compose([\n",
        "    transforms.Resize([int(600), int(600)], interpolation=transforms.InterpolationMode.BOX),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "# data_train_path 경로의 이미지를 transforms.Compose 로 정규화한 데이터 기준으로 트랜스폼\n",
        "train_data_set = datasets.ImageFolder(data_train_path, transform=transforms_train)\n",
        "val_data_set = datasets.ImageFolder(data_validation_path, transform=transforms_val)"
      ],
      "metadata": {
        "id": "c664y0wB02od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 로더 : 전처리한 이미지를 라벨링된 정답값과 튜플로 묶는다\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = DataLoader(train_data_set,\n",
        "                                  batch_size=hyper_param_batch,\n",
        "                                  shuffle=True,\n",
        "                                  num_workers=4)  #  check point  // aihub코드  num_workers = 4\n",
        "dataloaders['val'] = DataLoader(val_data_set,\n",
        "                                batch_size=hyper_param_batch,\n",
        "                                shuffle=False,\n",
        "                                num_workers=4)  # check point  // aihub코드  num_workers = 4\n",
        "batch_num['train'], batch_num['val'] = len(train_data_set), len(val_data_set)\n",
        "print('batch_size : %d,  train/val : %d / %d' % (hyper_param_batch, batch_num['train'], batch_num['val']))"
      ],
      "metadata": {
        "id": "CgNHg0mz2wFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습 펑션\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    if __name__ == '__main__':\n",
        "        start_time = time.time()\n",
        "        since = time.time()\n",
        "        best_acc = 0.0\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
        "        for epoch in tqdm(range(num_epochs)):\n",
        "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "            print('-' * 10)\n",
        "            epoch_start = time.time()\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # model.train()  ≫ 모델을 학습 모드로 변환\n",
        "                else:\n",
        "                    model.eval()  # model.eval()  ≫ 모델을 평가 모드로 변환\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "                num_cnt = 0\n",
        "                for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                    inputs = inputs.to(device) # 전처리한 이미지데이터\n",
        "                    labels = labels.to(device) # 이미지의 라벨링한 정답값\n",
        "                    optimizer.zero_grad()\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)  # 모델에 인풋(전처리한 이미지데이터)을 넣어서 아웃풋 생성\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)  # 로스 계산\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()  # backpropagation\n",
        "                            optimizer.step()  # weight update\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                    num_cnt += len(labels)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "                epoch_loss = float(running_loss / num_cnt)\n",
        "                epoch_acc = float((running_corrects.double() / num_cnt).cpu() * 100)\n",
        "                if phase == 'train':\n",
        "                    train_loss.append(epoch_loss)\n",
        "                    train_acc.append(epoch_acc)\n",
        "                else:\n",
        "                    val_loss.append(epoch_loss)\n",
        "                    val_acc.append(epoch_acc)\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_idx = epoch\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    print('==> best model saved - %d / %.1f' % (best_idx, best_acc))\n",
        "                epoch_end = time.time() - epoch_start\n",
        "                print('Training epochs {} in {:.0f}m {:.0f}s'.format(epoch, epoch_end // 60,epoch_end % 60))\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.1f' % (best_idx, best_acc))\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model, PATH + 'aram_' + train_name + '.pt')  # 모델을 PATH경로에 aram_트레인네임(model1).pt 라는 이름으로 저장한다\n",
        "    #torch.save(model.state_dict(), PATH + 'president_aram_' + train_name + '.pt')  # 모델의 매개변수 저장\n",
        "    print('model saved')\n",
        "    end_sec = time.time() - start_time\n",
        "    end_times = str(datetime.timedelta(seconds=end_sec)).split('.')\n",
        "    end_time = end_times[0]\n",
        "    print(\"end time :\", end_time)\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, val_loss, val_acc\n",
        "# def실행할 train_model 파라미터 선언\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "wKE5y_fby-Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def 실행\n",
        "train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)"
      ],
      "metadata": {
        "id": "RKK28B18y-KU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
