{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQr2E+PwL39G1OkoO4LgAh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeong777/Python-Quest/blob/main/hire_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN_Ibkv5Tpc-",
        "outputId": "5a9236d4-f7dc-4a2c-fe40-5da88b8a4ce4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=c330f8f3ec4d9f23e1e5263215130e88c1648ba93115714c8cb7a1a1ddda5bcd\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IyED1s4YRQja"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import copy\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from efficientnet_pytorch import EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBkU4rOlUdId",
        "outputId": "0112e80a-1354-415d-8ff5-47e7ca963e74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "hyper_param_batch = 6"
      ],
      "metadata": {
        "id": "fH8NiyLPRSbx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 100\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcIW09wQRSY4",
        "outputId": "9b125282-594d-4e83-ebd9-2a06a16ecad5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a8b4c7a53d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4\n",
        "model_name = 'efficientnet-b7'"
      ],
      "metadata": {
        "id": "ymR0tN4yRSWQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_name = 'model1'"
      ],
      "metadata": {
        "id": "HVU0m7ofRSTY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './scalp_weights/'"
      ],
      "metadata": {
        "id": "IhFF2rKKRSQw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/Colab Notebooks/train_data'"
      ],
      "metadata": {
        "id": "DChptj_v8xSq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_path = '/content/drive/MyDrive/Colab Notebooks/train_data/train'\n",
        "data_validation_path = '/content/drive/MyDrive/Colab Notebooks/train_data/validation'\n",
        "data_test_path = '/content/drive/MyDrive/Colab Notebooks/train_data/test'"
      ],
      "metadata": {
        "id": "z-ZJ6_ptYTuQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_path = '/train_data/'+train_name+'/train'\n",
        "data_validation_path = '/train_data/'+train_name+'/validation'\n",
        "data_test_path = '/train_data/'+train_name+'/test'"
      ],
      "metadata": {
        "id": "bPABpIZURSNw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = EfficientNet.get_image_size(model_name)\n",
        "print(image_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m0aVsR0RSEo",
        "outputId": "9fbb97a8-ad9c-49ca-e472-874477825a4f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axg2DqQDRZmb",
        "outputId": "5b6b248e-bb03-412a-cf2b-a632fd44cbb6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n",
            "100%|██████████| 254M/254M [00:01<00:00, 143MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(data_train_path):\n",
        "    os.makedirs(data_train_path)\n",
        "if not os.path.exists(data_validation_path):\n",
        "    os.makedirs(data_validation_path)\n",
        "if not os.path.exists(data_test_path):\n",
        "    os.makedirs(data_test_path)"
      ],
      "metadata": {
        "id": "pmgRIw6JqQgC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_train = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=4),\n",
        "                                        transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                        transforms.RandomVerticalFlip(p=0.5),\n",
        "                                        transforms.Lambda(lambda x: x.rotate(90)),\n",
        "                                        transforms.RandomRotation(10),\n",
        "                                        transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])"
      ],
      "metadata": {
        "id": "E9RKraz_RZjp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_val = transforms.Compose([\n",
        "                                        transforms.Resize([int(600), int(600)], interpolation=4),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                      ])"
      ],
      "metadata": {
        "id": "Uj0mq5VbRZhA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_path = '/content/drive/MyDrive/Colab Notebooks/train_data'\n",
        "data_validation_path = '/content/drive/MyDrive/Colab Notebooks/train_data'\n",
        "data_test_path = '/content/drive/MyDrive/Colab Notebooks/train_data'"
      ],
      "metadata": {
        "id": "FV9Vc_nPK5vR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_set = datasets.ImageFolder(data_train_path, transform=transforms_train)\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = DataLoader(train_data_set,\n",
        "                                    batch_size=hyper_param_batch,\n",
        "                                    shuffle=True,\n",
        "                                    num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT7QMVUYgUrO",
        "outputId": "f2f2477a-a288-4315-8822-6c5ddb966b81"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_set = datasets.ImageFolder(data_validation_path, transform=transforms_val)\n",
        "\n",
        "batch_num = {}\n",
        "batch_num['train'], batch_num['val'] = len(train_data_set), len(val_data_set)"
      ],
      "metadata": {
        "id": "xC6k2lE3N1-k"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('batch_size : %d,  train/val : %d / %d' % (hyper_param_batch, batch_num['train'], batch_num['val']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wKir7SBRZWS",
        "outputId": "02714805-6dec-4256-81ec-789db8858f9c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size : 6,  train/val : 1768 / 1768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "since = time.time()"
      ],
      "metadata": {
        "id": "SrAtgIo9eVZo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    start_time = time.time()\n",
        "\n",
        "    since = time.time()\n",
        "    best_acc = 0.0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            num_cnt = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "            else:\n",
        "                val_loss.append(epoch_loss)\n",
        "                val_acc.append(epoch_acc)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_idx = epoch\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
        "\n",
        "            epoch_end = time.time() - epoch_start\n",
        "\n",
        "            print('Training epochs {} in {:.0f}m {:.0f}s'.format(epoch, epoch_end // 60, epoch_end % 60))\n",
        "            print()\n",
        "\n",
        "            time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "\n",
        "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    torch.save(model, PATH + 'aram_'+train_name+'.pt')\n",
        "    torch.save(model.state_dict(), PATH + 'president_aram_'+train_name+'.pt')\n",
        "    print('model saved')\n",
        "\n",
        "    end_sec = time.time() - start_time\n",
        "    end_times = str(datetime.timedelta(seconds=end_sec)).split('.')\n",
        "    end_time = end_times[0]\n",
        "    print(\"end time :\", end_time)\n",
        "\n",
        "    return model, best_idx, best_acc, train_loss, train_acc, val_loss, val_acc"
      ],
      "metadata": {
        "id": "UkLOrQRiR8PZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 호출부분 추가\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37whP5g9cCZ8",
        "outputId": "37d1bcc5-8244-41f9-d905-4b59aa13ea3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ]
        }
      ]
    }
  ]
}